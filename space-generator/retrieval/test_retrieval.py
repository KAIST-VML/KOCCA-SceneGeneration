
import json
import re
import os
from typing import List, Dict, Tuple, Set
from collections import defaultdict, Counter
from difflib import SequenceMatcher
import math
import argparse


# ë°ì´í„°ë² ì´ìŠ¤ ì¹´í…Œê³ ë¦¬ ì •ì˜
_ATTR_STYLE = [
    {'id': 0, 'category': 'Modern'},
    {'id': 1, 'category': 'Chinoiserie'},
    {'id': 2, 'category': 'Kids'},
    {'id': 3, 'category': 'European'},
    {'id': 4, 'category': 'Japanese'},
    {'id': 5, 'category': 'Southeast Asia'},
    {'id': 6, 'category': 'Industrial'},
    {'id': 7, 'category': 'American Country'},
    {'id': 8, 'category': 'Vintage/Retro'},
    {'id': 9, 'category': 'Light Luxury'},
    {'id': 10, 'category': 'Mediterranean'},
    {'id': 11, 'category': 'Korean'},
    {'id': 12, 'category': 'New Chinese'},
    {'id': 13, 'category': 'Nordic'},
    {'id': 14, 'category': 'European Classic'},
    {'id': 15, 'category': 'Others'},
    {'id': 16, 'category': 'Ming Qing'},
    {'id': 17, 'category': 'Neoclassical'},
    {'id': 18, 'category': 'Minimalist'},
]

_ATTR_MATERIAL = [
    {'id': 0, 'category': 'Composition'},
    {'id': 1, 'category': 'Cloth'},
    {'id': 2, 'category': 'Leather'},
    {'id': 3, 'category': 'Glass'},
    {'id': 4, 'category': 'Metal'},
    {'id': 5, 'category': 'Solid Wood'},
    {'id': 6, 'category': 'Stone'},
    {'id': 7, 'category': 'Plywood'},
    {'id': 8, 'category': 'Others'},
    {'id': 9, 'category': 'Suede'},
    {'id': 10, 'category': 'Bamboo Rattan'},
    {'id': 11, 'category': 'Rough Cloth'},
    {'id': 12, 'category': 'Wood'},
    {'id': 13, 'category': 'Composite Board'},
    {'id': 14, 'category': 'Marble'},
    {'id': 15, 'category': 'Smooth Leather'},
]

_ATTR_THEME = [
    {'id': 0, 'category': 'Smooth Net'},
    {'id': 1, 'category': 'Lines'},
    {'id': 2, 'category': 'Wrought Iron'},
    {'id': 3, 'category': 'Cartoon'},
    {'id': 4, 'category': 'Granite Texture'},
    {'id': 5, 'category': 'Floral'},
    {'id': 6, 'category': 'Inlay Gold Carve'},
    {'id': 7, 'category': 'Texture Mark'},
    {'id': 8, 'category': 'Striped Grid'},
    {'id': 9, 'category': 'Chinese Pattern'},
    {'id': 10, 'category': 'Gold Foil'},
    {'id': 11, 'category': 'Rivet'},
    {'id': 12, 'category': 'Soft Case'},
    {'id': 13, 'category': 'Wooden Vertical Texture'},
    {'id': 14, 'category': 'Graffiti Ink Stain'},
    {'id': 15, 'category': 'Linen Texture'},
]

_SUPER_CATEGORIES_3D = [
    {'id': 1, 'category': 'Cabinet/Shelf/Desk'},
    {'id': 2, 'category': 'Bed'},
    {'id': 3, 'category': 'Chair'},
    {'id': 4, 'category': 'Table'},
    {'id': 5, 'category': 'Sofa'},
    {'id': 6, 'category': 'Pier/Stool'},
    {'id': 7, 'category': 'Lighting'},
    {'id': 8, 'category': 'Other'},
]

_CATEGORIES_3D = [
    {'id': 1, 'super-category': 'Cabinet/Shelf/Desk', 'category': 'Children Cabinet'},
    {'id': 2, 'super-category': 'Cabinet/Shelf/Desk', 'category': 'Nightstand'},
    {'id': 3, 'super-category': 'Cabinet/Shelf/Desk', 'category': 'Bookcase / jewelry Armoire'},
    {'id': 4, 'super-category': 'Cabinet/Shelf/Desk', 'category': 'Wardrobe'},
    {'id': 5, 'super-category': 'Cabinet/Shelf/Desk', 'category': 'Coffee Table'},
    {'id': 6, 'super-category': 'Cabinet/Shelf/Desk', 'category': 'Corner/Side Table'},
    {'id': 7, 'super-category': 'Cabinet/Shelf/Desk', 'category': 'Sideboard / Side Cabinet / Console Table'},
    {'id': 8, 'super-category': 'Cabinet/Shelf/Desk', 'category': 'Wine Cabinet'},
    {'id': 9, 'super-category': 'Cabinet/Shelf/Desk', 'category': 'TV Stand'},
    {'id': 10, 'super-category': 'Cabinet/Shelf/Desk', 'category': 'Drawer Chest / Corner cabinet'},
    {'id': 11, 'super-category': 'Cabinet/Shelf/Desk', 'category': 'Shelf'},
    {'id': 12, 'super-category': 'Cabinet/Shelf/Desk', 'category': 'Round End Table'},
    {'id': 13, 'super-category': 'Bed', 'category': 'King-size Bed'},
    {'id': 14, 'super-category': 'Bed', 'category': 'Bunk Bed'},
    {'id': 15, 'super-category': 'Bed', 'category': 'Bed Frame'},
    {'id': 16, 'super-category': 'Bed', 'category': 'Single bed'},
    {'id': 17, 'super-category': 'Bed', 'category': 'Kids Bed'},
    {'id': 18, 'super-category': 'Chair', 'category': 'Dining Chair'},
    {'id': 19, 'super-category': 'Chair', 'category': 'Lounge Chair / Cafe Chair / Office Chair'},
    {'id': 20, 'super-category': 'Chair', 'category': 'Dressing Chair'},
    {'id': 21, 'super-category': 'Chair', 'category': 'Classic Chinese Chair'},
    {'id': 22, 'super-category': 'Chair', 'category': 'Barstool'},
    {'id': 23, 'super-category': 'Table', 'category': 'Dressing Table'},
    {'id': 24, 'super-category': 'Table', 'category': 'Dining Table'},
    {'id': 25, 'super-category': 'Table', 'category': 'Desk'},
    {'id': 26, 'super-category': 'Sofa', 'category': 'Three-Seat / Multi-seat Sofa'},
    {'id': 27, 'super-category': 'Sofa', 'category': 'armchair'},
    {'id': 28, 'super-category': 'Sofa', 'category': 'Loveseat Sofa'},
    {'id': 29, 'super-category': 'Sofa', 'category': 'L-shaped Sofa'},
    {'id': 30, 'super-category': 'Sofa', 'category': 'Lazy Sofa'},
    {'id': 31, 'super-category': 'Sofa', 'category': 'Chaise Longue Sofa'},
    {'id': 32, 'super-category': 'Pier/Stool', 'category': 'Footstool / Sofastool / Bed End Stool / Stool'},
    {'id': 33, 'super-category': 'Lighting', 'category': 'Pendant Lamp'},
    {'id': 34, 'super-category': 'Lighting', 'category': 'Ceiling Lamp'},
    {'id': 35, 'super-category': 'Cabinet/Shelf/Desk', 'category': 'Shoe Cabinet'},
    {'id': 36, 'super-category': 'Bed', 'category': 'Couch Bed'},
    {'id': 37, 'super-category': 'Chair', 'category': 'Hanging Chair'},
    {'id': 38, 'super-category': 'Chair', 'category': 'Folding chair'},
    {'id': 39, 'super-category': 'Table', 'category': 'Bar'},
    {'id': 40, 'super-category': 'Sofa', 'category': 'U-shaped Sofa'},
    {'id': 41, 'super-category': 'Lighting', 'category': 'Floor Lamp'},
    {'id': 42, 'super-category': 'Lighting', 'category': 'Wall Lamp'},
]

class FurnitureSearchEngine:
    def __init__(self):
        self.style_categories = {item['category'].lower(): item['id'] for item in _ATTR_STYLE}
        self.material_categories = {item['category'].lower(): item['id'] for item in _ATTR_MATERIAL}
        self.theme_categories = {item['category'].lower(): item['id'] for item in _ATTR_THEME}
        self.super_categories = {item['category'].lower(): item['id'] for item in _SUPER_CATEGORIES_3D}
        
        # TF-IDFë¥¼ ìœ„í•œ ë¬¸ì„œ ì»¬ë ‰ì…˜ êµ¬ì¶•
        self.category_documents = [item['category'].lower() for item in _CATEGORIES_3D]
        self.build_tfidf_vectors()
        
    def build_tfidf_vectors(self):
        """TF-IDF ë²¡í„° êµ¬ì¶•"""
        # ì „ì²´ ë‹¨ì–´ ì§‘í•© êµ¬ì¶•
        all_words = set()
        document_words = []
        
        for doc in self.category_documents:
            words = self.tokenize(doc)
            document_words.append(words)
            all_words.update(words)
        
        self.vocabulary = sorted(all_words)
        self.word_to_idx = {word: idx for idx, word in enumerate(self.vocabulary)}
        
        # IDF ê³„ì‚°
        self.idf = {}
        total_docs = len(self.category_documents)
        
        for word in self.vocabulary:
            doc_freq = sum(1 for words in document_words if word in words)
            self.idf[word] = math.log(total_docs / (doc_freq + 1))
        
        # ê° ë¬¸ì„œì˜ TF-IDF ë²¡í„° ê³„ì‚°
        self.tfidf_vectors = []
        for words in document_words:
            vector = self.compute_tfidf_vector(words)
            self.tfidf_vectors.append(vector)
    
    def tokenize(self, text: str) -> List[str]:
        """í…ìŠ¤íŠ¸ í† í°í™” (ê°€êµ¬ ë„ë©”ì¸ íŠ¹í™”)"""
        text = text.lower()
        # ìŠ¬ë˜ì‹œ, í•˜ì´í”ˆ ë“±ì„ ê³µë°±ìœ¼ë¡œ ë³€í™˜
        text = re.sub(r'[/\-_]', ' ', text)
        # ì•ŒíŒŒë²³ê³¼ ìˆ«ìë§Œ ì¶”ì¶œ
        words = re.findall(r'\b\w+\b', text)
        
        # ë¶ˆìš©ì–´ ì œê±° (í¬ê¸° ê´€ë ¨ ìˆ˜ì‹ì–´)
        stopwords = {'small', 'large', 'big', 'mini', 'tiny', 'huge', 'size'}
        words = [w for w in words if w not in stopwords and len(w) > 1]
        
        return words
    
    def compute_tfidf_vector(self, words: List[str]) -> List[float]:
        """ë‹¨ì–´ ë¦¬ìŠ¤íŠ¸ë¡œë¶€í„° TF-IDF ë²¡í„° ê³„ì‚°"""
        word_count = Counter(words)
        total_words = len(words)
        
        vector = []
        for word in self.vocabulary:
            tf = word_count.get(word, 0) / total_words if total_words > 0 else 0
            idf = self.idf.get(word, 0)
            tfidf = tf * idf
            vector.append(tfidf)
        
        return vector
    
    def cosine_similarity(self, vec1: List[float], vec2: List[float]) -> float:
        """ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°"""
        dot_product = sum(a * b for a, b in zip(vec1, vec2))
        norm1 = math.sqrt(sum(a * a for a in vec1))
        norm2 = math.sqrt(sum(b * b for b in vec2))
        
        if norm1 == 0 or norm2 == 0:
            return 0.0
        
        return dot_product / (norm1 * norm2)
    
    def calculate_semantic_similarity(self, query_text: str, category_text: str) -> float:
        """ì˜ë¯¸ë¡ ì  ìœ ì‚¬ë„ ê³„ì‚° (TF-IDF + ì½”ì‚¬ì¸ ìœ ì‚¬ë„)"""
        query_words = self.tokenize(query_text)
        category_words = self.tokenize(category_text)
        
        query_vector = self.compute_tfidf_vector(query_words)
        category_vector = self.compute_tfidf_vector(category_words)
        
        return self.cosine_similarity(query_vector, category_vector)
    
    def jaccard_similarity(self, text1: str, text2: str) -> float:
        """Jaccard ìœ ì‚¬ë„ ê³„ì‚° (ë³´ì¡° ì§€í‘œ)"""
        words1 = set(self.tokenize(text1))
        words2 = set(self.tokenize(text2))
        
        if not words1 and not words2:
            return 1.0
        
        intersection = len(words1 & words2)
        union = len(words1 | words2)
        
        return intersection / union if union > 0 else 0.0
    
    def find_category_match(self, query_text: str) -> Tuple[str, str, float, str]:
        """ê°œì„ ëœ ì¹´í…Œê³ ë¦¬ ë§¤ì¹­ (TF-IDF ê¸°ë°˜)"""
        query_lower = query_text.lower().strip()
        
        # 1ë‹¨ê³„: Detail categoryì—ì„œ ì •í™•í•œ ë¬¸ìì—´ ë§¤ì¹­
        for item in _CATEGORIES_3D:
            category_lower = item['category'].lower()
            if query_lower == category_lower:
                print(f"âœ… ì •í™•í•œ ë§¤ì¹­: '{query_text}' â†’ {item['super-category']} / {item['category']}")
                return item['super-category'].lower(), item['category'], 1.0, "exact_match"
        
        # 2ë‹¨ê³„: TF-IDF + ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê¸°ë°˜ ë§¤ì¹­
        best_match = None
        best_score = 0.0
        best_super = None
        best_method = None
        
        for i, item in enumerate(_CATEGORIES_3D):
            # TF-IDF ì½”ì‚¬ì¸ ìœ ì‚¬ë„
            tfidf_similarity = self.calculate_semantic_similarity(query_text, item['category'])
            
            # Jaccard ìœ ì‚¬ë„ (ë³´ì¡°)
            jaccard_sim = self.jaccard_similarity(query_text, item['category'])
            
            # íŠ¹ë³„ ë§¤ì¹­ ì ìˆ˜
            special_score = self.get_special_match_score(query_text, item['category'])
            
            # ì¢…í•© ì ìˆ˜ ê³„ì‚° (TF-IDF ì¤‘ì‹¬, íŠ¹ë³„ ë§¤ì¹­ ë³´ê°•)
            if special_score > 0.8:  # íŠ¹ë³„ ë§¤ì¹­ì´ ê°•í•œ ê²½ìš°
                total_score = special_score * 0.7 + tfidf_similarity * 0.3
                method = "special+tfidf"
            else:  # ì¼ë°˜ì ì¸ ê²½ìš°
                total_score = tfidf_similarity * 0.8 + jaccard_sim * 0.2
                method = "tfidf+jaccard"
            
            if total_score > best_score:
                best_score = total_score
                best_match = item['category']
                best_super = item['super-category'].lower()
                best_method = method
        
        # ìœ ì‚¬ë„ê°€ ì¶©ë¶„íˆ ë†’ìœ¼ë©´ ì‚¬ìš©
        if best_score >= 0.25:  # ì„ê³„ê°’ ì¡°ì •
            print(f"âœ… ì˜ë¯¸ë¡ ì  ë§¤ì¹­: '{query_text}' â†’ {best_super} / {best_match}")
            print(f"   â””â”€â”€ ì ìˆ˜: {best_score:.3f} (ë°©ë²•: {best_method})")
            return best_super, best_match, best_score, "semantic_match"
        
        # 3ë‹¨ê³„: Super categoryì—ì„œ í‚¤ì›Œë“œ ë§¤ì¹­
        query_words = set(self.tokenize(query_text))
        for super_item in _SUPER_CATEGORIES_3D:
            super_category = super_item['category'].lower()
            super_words = set(self.tokenize(super_category))
            
            # í‚¤ì›Œë“œ êµì§‘í•© í™•ì¸
            if query_words & super_words:
                matched_keywords = query_words & super_words
                print(f"âœ… Super í‚¤ì›Œë“œ ë§¤ì¹­: '{query_text}' â†’ {super_category}")
                print(f"   â””â”€â”€ ë§¤ì¹­ëœ í‚¤ì›Œë“œ: {matched_keywords}")
                return super_category, None, 0.6, "super_keyword_match"
        
        # 4ë‹¨ê³„: Otherë¡œ fallback
        print(f"âš ï¸ '{query_text}' â†’ Otherë¡œ ë¶„ë¥˜")
        return 'other', None, 0.1, "other_fallback"
    
    def get_special_match_score(self, query: str, category: str) -> float:
        """íŠ¹ë³„í•œ ë§¤ì¹­ ì¼€ì´ìŠ¤ë“¤ ì²˜ë¦¬"""
        query_lower = query.lower()
        category_lower = category.lower()
        
        # ì§ì ‘ì ì¸ í¬í•¨ ê´€ê³„
        if 'chair' in query_lower and 'chair' in category_lower:
            return 1.0
        elif 'table' in query_lower and 'table' in category_lower:
            return 1.0
        elif 'cabinet' in query_lower and 'cabinet' in category_lower:
            return 1.0
        elif 'shelf' in query_lower and ('shelf' in category_lower or 'bookcase' in category_lower):
            return 1.0
        elif 'lamp' in query_lower and 'lamp' in category_lower:
            return 1.0
        elif 'bed' in query_lower and 'bed' in category_lower:
            return 1.0
        elif 'sofa' in query_lower and 'sofa' in category_lower:
            return 1.0
        elif 'stool' in query_lower and 'stool' in category_lower:
            return 1.0
        
        # íŠ¹ë³„í•œ ì˜ë¯¸ë¡ ì  ë§¤ì¹­
        elif 'bookshelf' in query_lower and ('bookcase' in category_lower or 'shelf' in category_lower):
            return 0.9
        elif 'filing' in query_lower and 'cabinet' in category_lower:
            return 0.8
        elif 'storage' in query_lower and ('cabinet' in category_lower or 'chest' in category_lower):
            return 0.7
        elif 'meeting' in query_lower and 'chair' in category_lower:
            return 0.6
        
        return 0.0
    
# ì „ì—­ í•¨ìˆ˜ë“¤ì„ í´ë˜ìŠ¤ ì™¸ë¶€ì— ì •ì˜
def parse_llm_furniture_text(text: str) -> List[Dict]:
    """LLM ê²°ê³¼ì—ì„œ ì¹´í…Œê³ ë¦¬ëª…ë§Œ ìœ ì—°í•˜ê²Œ ì¶”ì¶œ"""
    items = []
    
    # 1. ìˆ«ìë¡œ ì‹œì‘í•˜ëŠ” ì•„ì´í…œë“¤ ì°¾ê¸° (ë§¤ìš° ìœ ì—°í•œ íŒ¨í„´)
    # "1.", "1)", "1 -", "1:" ë“± ë‹¤ì–‘í•œ í˜•ì‹ ì§€ì›
    pattern = re.compile(r'^\s*(\d+)[\.\)\-:\s]+(.+?)(?=^\s*\d+[\.\)\-:\s]|\Z)', re.MULTILINE | re.DOTALL)
    matches = list(pattern.finditer(text))
    
    print(f"ğŸ” ë°œê²¬ëœ ì•„ì´í…œ: {len(matches)}ê°œ")
    
    for match in matches:
        item_number = match.group(1)
        item_content = match.group(2).strip()
        
        # 2. ì¹´í…Œê³ ë¦¬ ì¶”ì¶œ (ì²« ë²ˆì§¸ ì¤„ì—ì„œ *ì™€ : ì œê±°)
        lines = item_content.split('\n')
        first_line = lines[0].strip()
        
        # *ì™€ :ë¥¼ ëª¨ë‘ ì œê±°í•˜ê³  ìˆœìˆ˜ ì¹´í…Œê³ ë¦¬ëª…ë§Œ ì¶”ì¶œ
        category_name = re.sub(r'[\*\:]+', '', first_line).strip()
        
        print(f"  {item_number}: '{category_name}'")
        
        # 3. ì „ì²´ ì•„ì´í…œ í…ìŠ¤íŠ¸ (ì†ì„± ì¶”ì¶œìš©)
        item_data = {
            'item_number': int(item_number),
            'category_name': category_name,
            'full_text': item_content  # ê¸°ì¡´ _extract_section_keywordsì—ì„œ ì‚¬ìš©
        }
        
        items.append(item_data)
    
    return items

def extract_section_keywords_simple(text: str, section_name: str, style_categories: dict, material_categories: dict, theme_categories: dict) -> set:
    """ê°„ë‹¨í•œ ë°©ì‹ìœ¼ë¡œ ì„¹ì…˜ í‚¤ì›Œë“œ ì¶”ì¶œ"""
    found_keywords = set()
    
    # ì¤„ë³„ë¡œ ë‚˜ëˆ„ì–´ì„œ ì²˜ë¦¬
    lines = text.split('\n')
    
    for line in lines:
        line = line.strip()
        if not line.startswith('-'):
            continue
            
        # '-' ì œê±°
        content = line[1:].strip()
        
        # section_nameì´ í¬í•¨ëœ ì¤„ì¸ì§€ í™•ì¸ (ëŒ€ì†Œë¬¸ì ë¬´ì‹œ)
        if section_name.lower() not in content.lower():
            continue
            
        # íŠ¹ìˆ˜ê¸°í˜¸ì™€ section_name ì œê±°
        # ëª¨ë“  íŠ¹ìˆ˜ê¸°í˜¸(*:) ì œê±°í•˜ê³  section_nameë„ ì œê±°
        clean_content = re.sub(r'[\*\:]+', '', content)  # íŠ¹ìˆ˜ê¸°í˜¸ ì œê±°
        clean_content = re.sub(section_name, '', clean_content, flags=re.IGNORECASE)  # section_name ì œê±°
        clean_content = clean_content.strip().lower()
        
        print(f"    ğŸ“ {section_name} ì •ë¦¬ëœ í…ìŠ¤íŠ¸: {clean_content[:50]}...")
        
        if not clean_content:
            continue
            
        # í‚¤ì›Œë“œ ë§¤ì¹­
        for keyword in style_categories.keys():
            if keyword in clean_content:
                found_keywords.add(f"style:{keyword}")
        
        for keyword in material_categories.keys():
            if keyword in clean_content:
                found_keywords.add(f"material:{keyword}")
        
        for keyword in theme_categories.keys():
            if keyword in clean_content:
                found_keywords.add(f"theme:{keyword}")
    
    return found_keywords

class FurnitureSearchEngine:
    def __init__(self):
        self.style_categories = {item['category'].lower(): item['id'] for item in _ATTR_STYLE}
        self.material_categories = {item['category'].lower(): item['id'] for item in _ATTR_MATERIAL}
        self.theme_categories = {item['category'].lower(): item['id'] for item in _ATTR_THEME}
        self.super_categories = {item['category'].lower(): item['id'] for item in _SUPER_CATEGORIES_3D}
        
        # TF-IDFë¥¼ ìœ„í•œ ë¬¸ì„œ ì»¬ë ‰ì…˜ êµ¬ì¶•
        self.category_documents = [item['category'].lower() for item in _CATEGORIES_3D]
        self.build_tfidf_vectors()
        
    def build_tfidf_vectors(self):
        """TF-IDF ë²¡í„° êµ¬ì¶•"""
        # ì „ì²´ ë‹¨ì–´ ì§‘í•© êµ¬ì¶•
        all_words = set()
        document_words = []
        
        for doc in self.category_documents:
            words = self.tokenize(doc)
            document_words.append(words)
            all_words.update(words)
        
        self.vocabulary = sorted(all_words)
        self.word_to_idx = {word: idx for idx, word in enumerate(self.vocabulary)}
        
        # IDF ê³„ì‚°
        self.idf = {}
        total_docs = len(self.category_documents)
        
        for word in self.vocabulary:
            doc_freq = sum(1 for words in document_words if word in words)
            self.idf[word] = math.log(total_docs / (doc_freq + 1))
        
        # ê° ë¬¸ì„œì˜ TF-IDF ë²¡í„° ê³„ì‚°
        self.tfidf_vectors = []
        for words in document_words:
            vector = self.compute_tfidf_vector(words)
            self.tfidf_vectors.append(vector)
    
    def tokenize(self, text: str) -> List[str]:
        """í…ìŠ¤íŠ¸ í† í°í™” (ê°€êµ¬ ë„ë©”ì¸ íŠ¹í™”)"""
        text = text.lower()
        # ìŠ¬ë˜ì‹œ, í•˜ì´í”ˆ ë“±ì„ ê³µë°±ìœ¼ë¡œ ë³€í™˜
        text = re.sub(r'[/\-_]', ' ', text)
        # ì•ŒíŒŒë²³ê³¼ ìˆ«ìë§Œ ì¶”ì¶œ
        words = re.findall(r'\b\w+\b', text)
        
        # ë¶ˆìš©ì–´ ì œê±° (í¬ê¸° ê´€ë ¨ ìˆ˜ì‹ì–´)
        stopwords = {'small', 'large', 'big', 'mini', 'tiny', 'huge', 'size'}
        words = [w for w in words if w not in stopwords and len(w) > 1]
        
        return words
    
    def compute_tfidf_vector(self, words: List[str]) -> List[float]:
        """ë‹¨ì–´ ë¦¬ìŠ¤íŠ¸ë¡œë¶€í„° TF-IDF ë²¡í„° ê³„ì‚°"""
        word_count = Counter(words)
        total_words = len(words)
        
        vector = []
        for word in self.vocabulary:
            tf = word_count.get(word, 0) / total_words if total_words > 0 else 0
            idf = self.idf.get(word, 0)
            tfidf = tf * idf
            vector.append(tfidf)
        
        return vector
    
    def cosine_similarity(self, vec1: List[float], vec2: List[float]) -> float:
        """ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°"""
        dot_product = sum(a * b for a, b in zip(vec1, vec2))
        norm1 = math.sqrt(sum(a * a for a in vec1))
        norm2 = math.sqrt(sum(b * b for b in vec2))
        
        if norm1 == 0 or norm2 == 0:
            return 0.0
        
        return dot_product / (norm1 * norm2)
    
    def calculate_semantic_similarity(self, query_text: str, category_text: str) -> float:
        """ì˜ë¯¸ë¡ ì  ìœ ì‚¬ë„ ê³„ì‚° (TF-IDF + ì½”ì‚¬ì¸ ìœ ì‚¬ë„)"""
        query_words = self.tokenize(query_text)
        category_words = self.tokenize(category_text)
        
        query_vector = self.compute_tfidf_vector(query_words)
        category_vector = self.compute_tfidf_vector(category_words)
        
        return self.cosine_similarity(query_vector, category_vector)
    
    def jaccard_similarity(self, text1: str, text2: str) -> float:
        """Jaccard ìœ ì‚¬ë„ ê³„ì‚° (ë³´ì¡° ì§€í‘œ)"""
        words1 = set(self.tokenize(text1))
        words2 = set(self.tokenize(text2))
        
        if not words1 and not words2:
            return 1.0
        
        intersection = len(words1 & words2)
        union = len(words1 | words2)
        
        return intersection / union if union > 0 else 0.0
    
    def find_category_match(self, query_text: str) -> Tuple[str, str, float, str]:
        """ê°œì„ ëœ ì¹´í…Œê³ ë¦¬ ë§¤ì¹­ (TF-IDF ê¸°ë°˜)"""
        query_lower = query_text.lower().strip()
        
        # 1ë‹¨ê³„: Detail categoryì—ì„œ ì •í™•í•œ ë¬¸ìì—´ ë§¤ì¹­
        for item in _CATEGORIES_3D:
            category_lower = item['category'].lower()
            if query_lower == category_lower:
                print(f"âœ… ì •í™•í•œ ë§¤ì¹­: '{query_text}' â†’ {item['super-category']} / {item['category']}")
                return item['super-category'].lower(), item['category'], 1.0, "exact_match"
        
        # 2ë‹¨ê³„: TF-IDF + ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê¸°ë°˜ ë§¤ì¹­
        best_match = None
        best_score = 0.0
        best_super = None
        best_method = None
        
        for i, item in enumerate(_CATEGORIES_3D):
            # TF-IDF ì½”ì‚¬ì¸ ìœ ì‚¬ë„
            tfidf_similarity = self.calculate_semantic_similarity(query_text, item['category'])
            
            # Jaccard ìœ ì‚¬ë„ (ë³´ì¡°)
            jaccard_sim = self.jaccard_similarity(query_text, item['category'])
            
            # íŠ¹ë³„ ë§¤ì¹­ ì ìˆ˜
            special_score = self.get_special_match_score(query_text, item['category'])
            
            # ì¢…í•© ì ìˆ˜ ê³„ì‚° (TF-IDF ì¤‘ì‹¬, íŠ¹ë³„ ë§¤ì¹­ ë³´ê°•)
            if special_score > 0.8:  # íŠ¹ë³„ ë§¤ì¹­ì´ ê°•í•œ ê²½ìš°
                total_score = special_score * 0.7 + tfidf_similarity * 0.3
                method = "special+tfidf"
            else:  # ì¼ë°˜ì ì¸ ê²½ìš°
                total_score = tfidf_similarity * 0.8 + jaccard_sim * 0.2
                method = "tfidf+jaccard"
            
            if total_score > best_score:
                best_score = total_score
                best_match = item['category']
                best_super = item['super-category'].lower()
                best_method = method
        
        # ìœ ì‚¬ë„ê°€ ì¶©ë¶„íˆ ë†’ìœ¼ë©´ ì‚¬ìš©
        if best_score >= 0.25:  # ì„ê³„ê°’ ì¡°ì •
            print(f"âœ… ì˜ë¯¸ë¡ ì  ë§¤ì¹­: '{query_text}' â†’ {best_super} / {best_match}")
            print(f"   â””â”€â”€ ì ìˆ˜: {best_score:.3f} (ë°©ë²•: {best_method})")
            return best_super, best_match, best_score, "semantic_match"
        
        # 3ë‹¨ê³„: Super categoryì—ì„œ í‚¤ì›Œë“œ ë§¤ì¹­
        query_words = set(self.tokenize(query_text))
        for super_item in _SUPER_CATEGORIES_3D:
            super_category = super_item['category'].lower()
            super_words = set(self.tokenize(super_category))
            
            # í‚¤ì›Œë“œ êµì§‘í•© í™•ì¸
            if query_words & super_words:
                matched_keywords = query_words & super_words
                print(f"âœ… Super í‚¤ì›Œë“œ ë§¤ì¹­: '{query_text}' â†’ {super_category}")
                print(f"   â””â”€â”€ ë§¤ì¹­ëœ í‚¤ì›Œë“œ: {matched_keywords}")
                return super_category, None, 0.6, "super_keyword_match"
        
        # 4ë‹¨ê³„: Otherë¡œ fallback
        print(f"âš ï¸ '{query_text}' â†’ Otherë¡œ ë¶„ë¥˜")
        return 'other', None, 0.1, "other_fallback"
    
    def get_special_match_score(self, query: str, category: str) -> float:
        """íŠ¹ë³„í•œ ë§¤ì¹­ ì¼€ì´ìŠ¤ë“¤ ì²˜ë¦¬"""
        query_lower = query.lower()
        category_lower = category.lower()
        
        # ì§ì ‘ì ì¸ í¬í•¨ ê´€ê³„
        if 'chair' in query_lower and 'chair' in category_lower:
            return 1.0
        elif 'table' in query_lower and 'table' in category_lower:
            return 1.0
        elif 'cabinet' in query_lower and 'cabinet' in category_lower:
            return 1.0
        elif 'shelf' in query_lower and ('shelf' in category_lower or 'bookcase' in category_lower):
            return 1.0
        elif 'lamp' in query_lower and 'lamp' in category_lower:
            return 1.0
        elif 'bed' in query_lower and 'bed' in category_lower:
            return 1.0
        elif 'sofa' in query_lower and 'sofa' in category_lower:
            return 1.0
        elif 'stool' in query_lower and 'stool' in category_lower:
            return 1.0
        
        # íŠ¹ë³„í•œ ì˜ë¯¸ë¡ ì  ë§¤ì¹­
        elif 'bookshelf' in query_lower and ('bookcase' in category_lower or 'shelf' in category_lower):
            return 0.9
        elif 'filing' in query_lower and 'cabinet' in category_lower:
            return 0.8
        elif 'storage' in query_lower and ('cabinet' in category_lower or 'chest' in category_lower):
            return 0.7
        elif 'meeting' in query_lower and 'chair' in category_lower:
            return 0.6
        
        return 0.0
    
    def parse_structured_text_simple(self, text: str) -> List[Dict]:
        """LLM ê²°ê³¼ì˜ ê°„ë‹¨í•œ íŒŒì‹±"""
        llm_items = parse_llm_furniture_text(text)
        items = []
        
        for llm_item in llm_items:
            category_name = llm_item['category_name']
            item_text = llm_item['full_text']
            
            print(f"\nğŸ” ì²˜ë¦¬ ì¤‘: {category_name}")
            
            # ì¹´í…Œê³ ë¦¬ ë§¤ì¹­
            super_category, detailed_category, category_score, match_type = self.find_category_match(category_name)
            
            # ê°„ë‹¨í•œ í‚¤ì›Œë“œ ì¶”ì¶œ
            style_matches = extract_section_keywords_simple(
                item_text, "Style", 
                self.style_categories, self.material_categories, self.theme_categories
            )
            
            color_matches = extract_section_keywords_simple(
                item_text, "Color", 
                self.style_categories, self.material_categories, self.theme_categories
            )
            
            colour_matches = extract_section_keywords_simple(
                item_text, "Colour", 
                self.style_categories, self.material_categories, self.theme_categories
            )
            
            material_matches = extract_section_keywords_simple(
                item_text, "Material", 
                self.style_categories, self.material_categories, self.theme_categories
            )
            
            all_keywords = style_matches | color_matches | colour_matches | material_matches
            
            item_data = {
                'target_category': category_name,
                'super_category': super_category,
                'detailed_category': detailed_category,
                'category_score': category_score,
                'match_type': match_type,
                'style_keywords': style_matches,
                'color_keywords': color_matches | colour_matches,
                'material_keywords': material_matches,
                'all_keywords': all_keywords
            }
            
            items.append(item_data)
            
            if all_keywords:
                print(f"    ğŸ¯ í‚¤ì›Œë“œ: {', '.join(all_keywords)}")
            else:
                print(f"    âš ï¸ í‚¤ì›Œë“œ ì—†ìŒ")
        
        return items
    
    def parse_structured_text(self, text: str) -> List[Dict]:
        """ë©”ì¸ íŒŒì‹± í•¨ìˆ˜ - í˜¸í™˜ì„±ì„ ìœ„í•´ ì¶”ê°€"""
        return self.parse_structured_text_simple(text)
    
    def calculate_item_score(self, db_item: Dict, parsed_item: Dict) -> Tuple[float, Dict]:
        """ê°„ì†Œí™”ëœ ì ìˆ˜ ê³„ì‚°"""
        score = 0.0
        score_details = {}
        
        # Bed Frame ì œì™¸
        if (parsed_item['target_category'].lower() == 'bed' and 
            'bed frame' in db_item.get('category', '').lower()):
            return 0.0, {}
        
        db_super_category = db_item.get('super-category', '').lower()
        parsed_super_category = parsed_item['super_category']
        
        # Super category ë§¤ì¹­ í™•ì¸
        if db_super_category == parsed_super_category:
            # 1. ì¹´í…Œê³ ë¦¬ ë§¤ì¹­ ì ìˆ˜
            if parsed_item['match_type'] == 'exact_match':
                category_score = 25.0  # ì •í™•í•œ ë§¤ì¹­
            elif parsed_item['match_type'] == 'semantic_match':  # ìˆ˜ì •: similarity_match â†’ semantic_match
                category_score = 15.0 + (parsed_item['category_score'] * 10.0)  # ìœ ì‚¬ë„ ê¸°ë°˜
            elif parsed_item['match_type'] == 'super_keyword_match':
                category_score = 10.0  # Super í‚¤ì›Œë“œ ë§¤ì¹­
            else:
                category_score = 5.0  # Other ì¹´í…Œê³ ë¦¬
            
            score += category_score
            score_details['category_score'] = category_score
            
            # 2. Detail category ë§¤ì¹­ ì¶”ê°€ ì ìˆ˜
            if (parsed_item['detailed_category'] and 
                parsed_item['detailed_category'].lower() in db_item.get('category', '').lower()):
                detail_bonus = 15.0
                score += detail_bonus
                score_details['detail_bonus'] = detail_bonus
            
            # 3. Style, Material, Theme ì ìˆ˜ ì¶”ê°€
            style_score, material_score, theme_score = self._calculate_attribute_scores(db_item, parsed_item)
            score += style_score + material_score + theme_score
            
            if style_score > 0:
                score_details['style_score'] = style_score
            if material_score > 0:
                score_details['material_score'] = material_score  
            if theme_score > 0:
                score_details['theme_score'] = theme_score
                
        elif parsed_super_category == 'other':
            # Other ì¹´í…Œê³ ë¦¬ì¸ ê²½ìš° - ì†ì„±ë§Œìœ¼ë¡œ ì ìˆ˜ ê³„ì‚°
            base_score = 3.0
            score += base_score
            score_details['other_base'] = base_score
            
            # Style, Material, Theme ì ìˆ˜ë§Œ ê³„ì‚°
            style_score, material_score, theme_score = self._calculate_attribute_scores(db_item, parsed_item)
            score += style_score + material_score + theme_score
            
            if style_score > 0:
                score_details['style_score'] = style_score
            if material_score > 0:
                score_details['material_score'] = material_score
            if theme_score > 0:
                score_details['theme_score'] = theme_score
            
            # Otherì¸ë° ì†ì„± ë§¤ì¹­ì´ ì—†ìœ¼ë©´ 0ì 
            if style_score + material_score + theme_score == 0:
                return 0.0, {}
        
        return score, score_details
    
    def _calculate_attribute_scores(self, db_item: Dict, parsed_item: Dict) -> Tuple[float, float, float]:
        """Style, Material, Theme ì ìˆ˜ ê³„ì‚°"""
        style_matches = 0
        material_matches = 0
        theme_matches = 0
        
        for keyword in parsed_item['all_keywords']:
            if ':' not in keyword:
                continue
                
            category_type, category_name = keyword.split(':', 1)
            
            if category_type == 'style' and category_name in db_item.get('style', '').lower():
                style_matches += 1
            elif category_type == 'material' and category_name in db_item.get('material', '').lower():
                material_matches += 1
            elif category_type == 'theme' and category_name in db_item.get('theme', '').lower():
                theme_matches += 1
        
        # ì ìˆ˜ ê³„ì‚°
        style_score = style_matches * 3.0
        material_score = material_matches * 2.0
        theme_score = theme_matches * 2.0
        
        return style_score, material_score, theme_score

class DatabaseLoader:
    """ì‹¤ì œ ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ model_info.json íŒŒì¼ë“¤ì„ ë¡œë“œ"""
    
    @staticmethod
    def load_multiple_folders(folder_paths: List[str]) -> List[Dict]:
        """ì—¬ëŸ¬ í´ë”ì—ì„œ model_info.json íŒŒì¼ë“¤ì„ ë¡œë“œ"""
        database = []
        seen_model_ids = set()  # ì¤‘ë³µ ì²´í¬ìš©
        duplicate_count = 0
        
        for i, folder_path in enumerate(folder_paths, 1):
            if not os.path.exists(folder_path):
                continue
                
            model_info_path = os.path.join(folder_path, "model_info.json")
            
            if os.path.exists(model_info_path):
                try:
                    with open(model_info_path, 'r', encoding='utf-8') as f:
                        model_data = json.load(f)
                    
                    folder_name = os.path.basename(folder_path)
                    
                    if isinstance(model_data, list):
                        for item in model_data:
                            model_id = item.get('model_id')
                            
                            if model_id and model_id in seen_model_ids:
                                duplicate_count += 1
                                continue
                            
                            if model_id:
                                seen_model_ids.add(model_id)
                            
                            item['source_folder'] = folder_name
                            item['source_path'] = folder_path
                            database.append(item)
                    else:
                        model_id = model_data.get('model_id')
                        
                        if model_id and model_id in seen_model_ids:
                            duplicate_count += 1
                        else:
                            if model_id:
                                seen_model_ids.add(model_id)
                            model_data['source_folder'] = folder_name
                            model_data['source_path'] = folder_path
                            database.append(model_data)
                        
                except Exception as e:
                    continue
        
        print(f"âœ… ì¤‘ë³µ ì œê±° ì™„ë£Œ: {duplicate_count}ê°œ ì¤‘ë³µ í•­ëª© ì œê±°ë¨")
        return database

def save_results_to_files(results_by_object: Dict, output_dir: str = "./search_results"):
    """ê²€ìƒ‰ ê²°ê³¼ë¥¼ objectë³„ë¡œ í…ìŠ¤íŠ¸ íŒŒì¼ì— ì €ì¥ (IDë§Œ)"""
    os.makedirs(output_dir, exist_ok=True)
    
    for object_name, results in results_by_object.items():
        # íŒŒì¼ëª…ì—ì„œ íŠ¹ìˆ˜ë¬¸ì ì œê±° ë˜ëŠ” ì•ˆì „í•˜ê²Œ ë³€í™˜
        safe_name = object_name.replace('/', '_').replace('\\', '_').replace('(', '').replace(')', '').replace(':', '_')
        filename = f"{safe_name}_results.txt"
        filepath = os.path.join(output_dir, filename)
        
        try:
            with open(filepath, 'w', encoding='utf-8') as f:
                for item, score in results:
                    f.write(f"{item.get('model_id', 'N/A')}\n")
            
            print(f"âœ… {object_name} ê²°ê³¼ ì €ì¥ë¨: {filepath} ({len(results)}ê°œ ID)")
        except Exception as e:
            print(f"âŒ {object_name} ì €ì¥ ì‹¤íŒ¨: {e}")

def search_furniture_database(folder_paths: List[str], query_text: str, output_dir: str = "./search_results"):
    """ì‹¤ì œ ë°ì´í„°ë² ì´ìŠ¤ë¥¼ ì‚¬ìš©í•œ ê°€êµ¬ ê²€ìƒ‰ (ê°„ì†Œí™”ëœ ë²„ì „)"""
    
    # ê²€ìƒ‰ ì—”ì§„ ì´ˆê¸°í™”
    search_engine = FurnitureSearchEngine()
    
    # ë°ì´í„°ë² ì´ìŠ¤ ë¡œë“œ
    print("=== ë°ì´í„°ë² ì´ìŠ¤ ë¡œë”© ì¤‘... ===")
    database = DatabaseLoader.load_multiple_folders(folder_paths)
    
    if not database:
        print("ë°ì´í„°ë² ì´ìŠ¤ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤!")
        return
    
    print(f"ì´ {len(database)}ê°œ ì•„ì´í…œ ë¡œë“œ ì™„ë£Œ")
    
    # None ê°’ ì •ë¦¬
    fields_to_clean = ['material', 'style', 'theme', 'super-category', 'category']
    cleaned_count = 0

    for item in database:
        for field in fields_to_clean:
            if item.get(field) is None:
                item[field] = ''
                cleaned_count += 1

    print(f"None ê°’ {cleaned_count}ê°œ ì •ë¦¬ ì™„ë£Œ")

    # í…ìŠ¤íŠ¸ íŒŒì‹± - ìˆ˜ì •ëœ ë©”ì„œë“œ ì´ë¦„ ì‚¬ìš©
    print("\n=== ì¹´í…Œê³ ë¦¬ ë§¤ì¹­ ê²°ê³¼ ===")
    parsed_items = search_engine.parse_structured_text(query_text)  # parse_structured_text ì‚¬ìš©
    
    if not parsed_items:
        print("íŒŒì‹±ëœ ì•„ì´í…œì´ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    print(f"\nì´ {len(parsed_items)}ê°œ ì•„ì´í…œì´ ì„±ê³µì ìœ¼ë¡œ ë§¤ì¹­ë¨")
    
    # ê° objectë³„ë¡œ ê²€ìƒ‰ ê²°ê³¼ ì €ì¥
    results_by_object = {}
    
    for parsed_item in parsed_items:
        target_category = parsed_item['target_category']
        
        # í•´ë‹¹ objectì— ëŒ€í•œ ëª¨ë“  ê²°ê³¼ ê³„ì‚°
        object_results = []
        matched_count = 0
        
        for db_item in database:
            score, details = search_engine.calculate_item_score(db_item, parsed_item)
            
            if score > 0:
                object_results.append((db_item, score))
                matched_count += 1
        
        # ì ìˆ˜ìˆœìœ¼ë¡œ ì •ë ¬
        object_results.sort(key=lambda x: x[1], reverse=True)
        
        # ìƒìœ„ 2ê°œ ì ìˆ˜ëŒ€ì˜ ëª¨ë“  ì•„ì´í…œ ì¶”ì¶œ
        if object_results:
            unique_scores = list(set(item[1] for item in object_results))
            unique_scores.sort(reverse=True)
            top_2_scores = unique_scores[:2]
            
            top_results = [item for item in object_results if item[1] in top_2_scores]
            
            score_summary = ", ".join([f"{score}ì ({sum(1 for item in object_results if item[1] == score)}ê°œ)" 
                                     for score in top_2_scores])
        else:
            top_results = []
            score_summary = "ê²°ê³¼ ì—†ìŒ"
        
        results_by_object[target_category] = top_results
        
        print(f"ğŸ” {target_category.upper()}: ë§¤ì¹­ {matched_count}ê°œ â†’ ìƒìœ„ 2ì ìˆ˜ëŒ€ [{score_summary}] â†’ ê²°ê³¼ {len(top_results)}ê°œ")
    
    # ê²°ê³¼ë¥¼ íŒŒì¼ì— ì €ì¥
    save_results_to_files(results_by_object, output_dir)
    
    # ìš”ì•½ í†µê³„ ì¶œë ¥
    total_results = sum(len(results) for results in results_by_object.values())
    print(f"\n{'='*60}")
    print(f"ğŸ¯ ê²€ìƒ‰ ì™„ë£Œ!")
    print(f"ğŸ“ ê²°ê³¼ ì €ì¥ ìœ„ì¹˜: {output_dir}")
    print(f"ğŸ“Š ì´ {len(parsed_items)}ê°œ Object, {total_results}ê°œ ê²°ê³¼")
    for obj_name, results in results_by_object.items():
        print(f"   - {obj_name}: {len(results)}ê°œ")
    print(f"{'='*60}")
    
    return results_by_object

# ì‚¬ìš© ì˜ˆì‹œ
def demo_search(query_text_path, output_dir):
    # ì‹¤ì œ ë°ì´í„°ë² ì´ìŠ¤ í´ë” ê²½ë¡œë“¤
    DATASET_BASE_PATH = os.environ.get('DATASET_BASE_PATH', '../../dataset')

    folder_paths = [
        os.path.join(DATASET_BASE_PATH, "3D-FUTURE-model-part1"),
        os.path.join(DATASET_BASE_PATH, "3D-FUTURE-model-part2"),
        os.path.join(DATASET_BASE_PATH, "3D-FUTURE-model-part3"),
        os.path.join(DATASET_BASE_PATH, "3D-FUTURE-model-part4")
    ]
    
    with open(query_text_path, "r", encoding="utf-8") as f:
        query_text = f.read()
        
    search_furniture_database(folder_paths, query_text, output_dir)

if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="Furniture category & keyword matching")

    parser.add_argument(
        "--layout_path", type=str, default = "Result_txt/test.txt", required=True,
        help="Path to the layout.txt file (LLM prompt result)"
    )

    parser.add_argument(
        "--output_dir", type=str, default = "Result_txt/text_retrieval", required=True,
        help="Directory where the results will be saved"
    )

    args = parser.parse_args()

    demo_search(args.layout_path, args.output_dir)